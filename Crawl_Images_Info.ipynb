{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9LCMrlGUF2C",
        "outputId": "c04fcb2e-a68d-4fba-b0b3-ef4a47e20439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.5.0-py3-none-any.whl (995 kB)\n",
            "\u001b[K     |████████████████████████████████| 995 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
            "\u001b[K     |████████████████████████████████| 384 kB 39.9 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.7/dist-packages (from selenium) (2022.9.24)\n",
            "Collecting urllib3[socks]~=1.26\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 42.6 MB/s \n",
            "\u001b[?25hCollecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting exceptiongroup>=1.0.0rc9\n",
            "  Downloading exceptiongroup-1.0.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (22.1.0)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, exceptiongroup, async-generator, wsproto, urllib3, trio, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.12 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 exceptiongroup-1.0.0 h11-0.14.0 outcome-1.2.0 selenium-4.5.0 sniffio-1.3.0 trio-0.22.0 trio-websocket-0.9.2 urllib3-1.26.12 wsproto-1.2.0\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,217 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,467 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,257 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,332 kB]\n",
            "Fetched 8,553 kB in 5s (1,575 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 91.7 MB of archives.\n",
            "After this operation, 309 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 105.0.5195.102-0ubuntu0.18.04.1 [1,156 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 105.0.5195.102-0ubuntu0.18.04.1 [80.1 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 105.0.5195.102-0ubuntu0.18.04.1 [5,097 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 105.0.5195.102-0ubuntu0.18.04.1 [5,320 kB]\n",
            "Fetched 91.7 MB in 4s (23.6 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 123942 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_105.0.5195.102-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_105.0.5195.102-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_105.0.5195.102-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_105.0.5195.102-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFzTva1eUQ9I",
        "outputId": "8a361519-a560-4fbc-efc0-ec89764478a7"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "None\n",
            "hereee\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plane: Decubitus , 17\n",
            "link 1 ....\n",
            "link 2 ....\n",
            "link 3 ....\n",
            "link 4 ....\n",
            "link 5 ....\n",
            "link 6 ....\n",
            "link 7 ....\n",
            "link 8 ....\n",
            "link 9 ....\n",
            "link 10 ....\n",
            "link 11 ....\n",
            "link 12 ....\n",
            "link 13 ....\n",
            "link 14 ....\n",
            "link 15 ....\n",
            "link 16 ....\n",
            "link 17 ....\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Download_images.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1OcELHfJsM1YrIvMg31UTMECJw8DDd3i3\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import re\n",
        "import json\n",
        "import os\n",
        "import errno\n",
        "from multiprocessing import Pool\n",
        "from pathlib import Path\n",
        "import ssl\n",
        "import time\n",
        "import urllib\n",
        "from urllib.request import urlopen\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/MedPix Dataset'\n",
        "\n",
        "\n",
        "\n",
        "links_dict = {\n",
        "             'AP': \"https://medpix.nlm.nih.gov/search?pln=%5B%22AP%22%5D&allen=true&allt=true&alli=true\",\n",
        "            'Axical' : \"https://medpix.nlm.nih.gov/search?pln=%5B%22Axial%22%5D&allen=true&allt=true&alli=true\",\n",
        "            'Coronal' : \"https://medpix.nlm.nih.gov/search?pln=%5B%22Coronal%22%5D&allen=true&allt=true&alli=true\",\n",
        "             'Frontal' : 'https://medpix.nlm.nih.gov/search?pln=%5B%22Frontal%22%5D&allen=true&allt=true&alli=true',\n",
        "              'Histology' : 'https://medpix.nlm.nih.gov/search?pln=%5B%22Histology%22%5D&allen=true&allt=true&alli=true',\n",
        "              'Image-Plane' : 'https://medpix.nlm.nih.gov/search?pln=%5B%22Image%20Plane%22%5D&allen=true&allt=true&alli=true',\n",
        "              'Lateral' : 'https://medpix.nlm.nih.gov/search?pln=%5B%22Lateral%22%5D&allen=true&allt=true&alli=true',\n",
        "              'Longitudinal' : 'https://medpix.nlm.nih.gov/search?pln=%5B%22Longitudinal%22%5D&allen=true&allt=true&alli=true',\n",
        "              'Mammo-CC' : 'https://medpix.nlm.nih.gov/search?pln=%5B%22Mammo%20-%20CC%22%5D&allen=true&allt=true&alli=true',\n",
        "              'Mammo-MagCC' : 'https://medpix.nlm.nih.gov/search?pln=%5B%22Mammo%20-%20Mag%20CC%22%5D&allen=true&allt=true&alli=true',\n",
        "              'Mammo-MLO' : 'https://medpix.nlm.nih.gov/search?pln=%5B%22Mammo%20-%20MLO%22%5D&allen=true&allt=true&alli=true',\n",
        "              'Multiple-or-Montage' : 'https://medpix.nlm.nih.gov/search?pln=%5B%22Multiple%20or%20Montage%22%5D&allen=true&allt=true&alli=true',\n",
        "              'NOS' : 'https://medpix.nlm.nih.gov/search?pln=%5B%22NOS%20-%20Not%20specified%22%5D&allen=true&allt=true&alli=true',\n",
        "              'Oblique' : 'https://medpix.nlm.nih.gov/search?pln=%5B%22Oblique%22%5D&allen=true&allt=true&alli=true',\n",
        "              'Other-view' : 'https://medpix.nlm.nih.gov/search?pln=%5B%22Other%20View%20(see%20caption)%22%5D&allen=true&allt=true&alli=true',\n",
        "              'PA' : 'https://medpix.nlm.nih.gov/search?pln=%5B%22PA%22%5D&allen=true&allt=true&alli=true',\n",
        "              'Sagittal' : 'https://medpix.nlm.nih.gov/search?pln=%5B%22Sagittal%22%5D&allen=true&allt=true&alli=true',\n",
        "              'Transverse' : 'https://medpix.nlm.nih.gov/search?pln=%5B%22Transverse%22%5D&allen=true&allt=true&alli=true',\n",
        "              '3D-Reconstruction' : 'https://medpix.nlm.nih.gov/search?pln=%5B%223D%20Reconstruction%22%5D&allen=true&allt=true&alli=true'\n",
        "}\n",
        "\n",
        "def save_to_json_file(current_path,new_data):\n",
        "  myfile = Path(current_path +'/new_dataset.json')\n",
        "  myfile.touch(exist_ok=True)\n",
        "  with open(f'{current_path}/new_dataset.json', 'r', encoding='utf-8') as f:\n",
        "    try:\n",
        "        data = json.load(f)\n",
        "    except ValueError:\n",
        "         data = []\n",
        "  with open(f'{current_path}/new_dataset.json', 'w', encoding='utf-8') as f:\n",
        "    data = data + new_data\n",
        "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "path_to_file = dataset_path+'/checkpoint.txt'\n",
        "path = Path(path_to_file)\n",
        "print(path.is_file())\n",
        "\n",
        "if path.is_file():\n",
        "    with open(dataset_path+'/checkpoint.txt','r') as f:\n",
        "        lines = f.readlines()\n",
        "        curr_plane , index = lines[0].strip() , int(lines[1])\n",
        "        print(curr_plane, index)\n",
        "else:\n",
        "    curr_plane , index = None , 0\n",
        "\n",
        "for plane in links_dict:\n",
        "    print(curr_plane)\n",
        "    if (not curr_plane is None) and (plane != curr_plane):\n",
        "        continue\n",
        "    print('hereee')\n",
        "    link = links_dict[plane]\n",
        "    current_path = dataset_path+'/'+plane\n",
        "    download_path = current_path + \"/new_images\"\n",
        "    os.makedirs(download_path, exist_ok=True)\n",
        "    with open(current_path+'/image_links.txt', 'r', encoding='utf-8') as f:\n",
        "        links = f.readlines()\n",
        "        links = list(set(links))\n",
        "        links = links[index:]\n",
        "        data = []\n",
        "        driver = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "        wait = WebDriverWait(driver, 15)\n",
        "        print('plane: '+plane+' , '+str(len(links)))\n",
        "        for link in links:\n",
        "            if link is None:\n",
        "                continue\n",
        "            print('link '+str(index+1)+' ....')\n",
        "            try:\n",
        "                driver.get(link)\n",
        "            except:\n",
        "                try:\n",
        "                    driver.get(link)\n",
        "                except:\n",
        "                    pass\n",
        "            finally:\n",
        "                with open(dataset_path+'/checkpoint.txt','w') as f:\n",
        "                    f.write(plane + \"\\n \")\n",
        "                    f.write(str(index)+\"\\n\")\n",
        "            time.sleep(5)  # Allow 4 seconds for the web page to open\n",
        "\n",
        "            title = wait.until(EC.visibility_of_element_located((By.CLASS_NAME, 'image-title')))\n",
        "            title = title.text\n",
        "            image_link = driver.find_element(by=By.CLASS_NAME, value='image-frame').find_element(by=By.TAG_NAME, value='img')\n",
        "            image_link = image_link.get_attribute('src')\n",
        "\n",
        "            contents = driver.find_element(by=By.ID, value=\"left-section\")\n",
        "            contents = contents.text.split('\\n')\n",
        "            caption = contents[contents.index('Caption') + 1] if \"Caption\" in contents else None\n",
        "            plane = contents[contents.index('Plane') + 1] if \"Plane\" in contents else None\n",
        "            modality = contents[contents.index('Modality') + 1] if \"Modality\" in contents else None\n",
        "            demographics = contents[contents.index('Demographics') + 1] if \"Demographics\" in contents else None\n",
        "\n",
        "            topic_sec = driver.find_element(by=By.LINK_TEXT, value=\"Topic\")\n",
        "            if topic_sec is None:\n",
        "                continue\n",
        "            topic_sec.click()\n",
        "            time.sleep(3)\n",
        "            contents = driver.find_element(by=By.ID, value=\"image-tab-content\")\n",
        "            if contents.text != 'No related topic found.':\n",
        "                contents = driver.find_element(by=By.ID, value=\"image-tab-content\").text\n",
        "                contents = contents.split('\\n')\n",
        "                topic = contents[contents.index('TOPIC') + 1] if \"TOPIC\" in contents else None\n",
        "                disease_discussion = contents[contents.index('Disease Discussion') + 1] if \"Disease Discussion\" in contents else None\n",
        "                location = contents[contents.index('Location') + 1] if \"Location\" in contents else None\n",
        "                category = contents[contents.index('Category') + 1] if \"Category\" in contents else None\n",
        "                refrence_idx = contents.index('Reference') if 'Reference' in contents else len(contents)\n",
        "                keywords = []\n",
        "                if \"Keywords\" in contents:\n",
        "                    if \"Category\" in contents:\n",
        "                      keywords = contents[contents.index('Category') + 1 : refrence_idx ]\n",
        "            else:\n",
        "                topic = None; disease_discussion = None; location = None; category = None ; keywords = []\n",
        "\n",
        "            entry = { 'id': index, 'title' : title, 'image_link' : image_link, 'caption': caption, 'plane' : plane, 'modality' : modality, 'demographics': demographics\n",
        "                 ,'topic': topic, 'disease_discussion' : disease_discussion, 'location': location, 'category': category}\n",
        "\n",
        "\n",
        "            if image_link is None:\n",
        "                continue\n",
        "\n",
        "            save_to_json_file(current_path, [entry])\n",
        "\n",
        "\n",
        "            img_data = requests.get(image_link).content\n",
        "            with open(download_path+'/'+plane+'_'+str(index)+'.jpg', 'wb') as handler:\n",
        "                handler.write(img_data)\n",
        "\n",
        "            index += 1\n",
        "\n",
        "        curr_plane , index = None , 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah7tuQKmfoSX"
      },
      "outputs": [],
      "source": [
        "directory_list = ['AP', 'Axial', 'Coronal', 'Frontal', 'Histology', 'Image-Plane','Lateral','Longitudinal',\n",
        "                  'Mammo-CC','Mammo-MagCC','Mammo-MLO','Multiple or Montage','NOS','Oblique','Other view','PA','3D Reconstruction', 'Transverse', 'Sagittal', 'Decubitus' ]\n",
        "sum = 0\n",
        "for plane in directory_list:\n",
        "  current_path = dataset_path+'/'+plane\n",
        "  with open(f'{current_path}/new_dataset.json', 'r', encoding='utf-8') as f:\n",
        "    try:\n",
        "        data = json.load(f)\n",
        "    except ValueError:\n",
        "        data = []\n",
        "  sum += len(data)\n",
        "  print(f'{plane} : {len(data)}')\n",
        "print(sum)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory_list = ['AP', 'Axial', 'Coronal', 'Frontal', 'Histology', 'Image-Plane','Lateral','Longitudinal',\n",
        "                  'Mammo-CC','Mammo-MagCC','Mammo-MLO','Multiple or Montage','NOS','Oblique','Other view','PA','3D Reconstruction', 'Transverse', 'Sagittal', 'Decubitus' ]\n",
        "sum = 0\n",
        "for plane in directory_list:\n",
        "  current_path = dataset_path+'/'+plane + '/' +\n",
        "image_list = list(glob.glob(path + 'train/*.jpg'))\n",
        "len(image_list)"
      ],
      "metadata": {
        "id": "sqJPL6vJXkr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import os\n",
        "import errno\n",
        "from multiprocessing import Pool\n",
        "from pathlib import Path\n",
        "import ssl\n",
        "import time\n",
        "import urllib\n",
        "from urllib.request import urlopen\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import glob\n",
        "\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/MedPix Dataset'"
      ],
      "metadata": {
        "id": "EQAVTvORg3Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_json_file(current_path,new_data):\n",
        "  myfile = Path(current_path +'/r_dataset.json')\n",
        "  myfile.touch(exist_ok=True)\n",
        "  with open(f'{current_path}/r_dataset.json', 'r', encoding='utf-8') as f:\n",
        "    try:\n",
        "        data = json.load(f)\n",
        "    except ValueError:\n",
        "         data = []\n",
        "  with open(f'{current_path}/r_dataset.json', 'w', encoding='utf-8') as f:\n",
        "    data = data + new_data\n",
        "    json.dump(data, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "eMTEWKVFlG77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory_list = ['AP', 'Axial', 'Coronal', 'Frontal', 'Histology', 'Image-Plane','Lateral','Longitudinal',\n",
        "                  'Mammo-CC','Mammo-MagCC','Mammo-MLO','Multiple or Montage','NOS','Oblique','Other view','PA','3D Reconstruction', 'Transverse', 'Sagittal', 'Decubitus' ]\n",
        "\n",
        "for plane in directory_list:\n",
        "  print(plane)\n",
        "  current_path = dataset_path+'/'+plane\n",
        "  image_list = list(glob.glob(current_path + '/new_images/*.jpg'))\n",
        "  with open(f'{current_path}/r_dataset.json', 'r', encoding='utf-8') as f:\n",
        "    try:\n",
        "        data = json.load(f)\n",
        "    except ValueError:\n",
        "        data = []\n",
        "  print(len(data))\n",
        "  print(len(image_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY7ITbpYmISz",
        "outputId": "b41c1124-5860-4be5-9b3f-3b0ded21b2d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AP\n",
            "1446\n",
            "1446\n",
            "Axial\n",
            "7250\n",
            "7250\n",
            "Coronal\n",
            "2824\n",
            "2824\n",
            "Frontal\n",
            "1016\n",
            "1016\n",
            "Histology\n",
            "348\n",
            "348\n",
            "Image-Plane\n",
            "182\n",
            "182\n",
            "Lateral\n",
            "1165\n",
            "1165\n",
            "Longitudinal\n",
            "300\n",
            "300\n",
            "Mammo-CC\n",
            "116\n",
            "116\n",
            "Mammo-MagCC\n",
            "12\n",
            "12\n",
            "Mammo-MLO\n",
            "113\n",
            "113\n",
            "Multiple or Montage\n",
            "320\n",
            "320\n",
            "NOS\n",
            "926\n",
            "926\n",
            "Oblique\n",
            "382\n",
            "382\n",
            "Other view\n",
            "423\n",
            "423\n",
            "PA\n",
            "656\n",
            "656\n",
            "3D Reconstruction\n",
            "232\n",
            "232\n",
            "Transverse\n",
            "488\n",
            "488\n",
            "Sagittal\n",
            "3031\n",
            "3031\n",
            "Decubitus\n",
            "17\n",
            "17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory_list = ['AP', 'Axial', 'Coronal', 'Frontal', 'Histology', 'Image-Plane','Lateral','Longitudinal',\n",
        "                  'Mammo-CC','Mammo-MagCC','Mammo-MLO','Multiple or Montage','NOS','Oblique','Other view','PA','3D Reconstruction', 'Transverse', 'Sagittal', 'Decubitus' ]\n",
        "\n",
        "for plane in directory_list:\n",
        "  print(plane)\n",
        "  current_path = dataset_path+'/'+plane\n",
        "  with open(f'{current_path}/new_dataset.json', 'r', encoding='utf-8') as f:\n",
        "    try:\n",
        "        data = json.load(f)\n",
        "    except ValueError:\n",
        "        data = []\n",
        "  print(len(data))\n",
        "  image_list = list(glob.glob(current_path + '/new_images/*.jpg'))\n",
        "  image_ids = []\n",
        "  for image in image_list:\n",
        "    image_ids.append(int(image.split('/')[-1].split('.')[0].split('_')[-1]))\n",
        "\n",
        "  new_data = []\n",
        "  for i in range(len(data)):\n",
        "    if data[i]['id'] in image_ids:\n",
        "      new_data.append(data[i])\n",
        "  print(len(new_data))\n",
        "  save_to_json_file(current_path,new_data)\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzhAps7Fg8bS",
        "outputId": "7516c63f-ed82-41dd-9191-2780fbd72975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AP\n",
            "1446\n",
            "1446\n",
            "Axial\n",
            "7251\n",
            "7251\n",
            "Coronal\n",
            "5649\n",
            "5649\n",
            "Frontal\n",
            "1016\n",
            "1016\n",
            "Histology\n",
            "349\n",
            "349\n",
            "Image-Plane\n",
            "182\n",
            "182\n",
            "Lateral\n",
            "1165\n",
            "1165\n",
            "Longitudinal\n",
            "303\n",
            "303\n",
            "Mammo-CC\n",
            "116\n",
            "116\n",
            "Mammo-MagCC\n",
            "12\n",
            "12\n",
            "Mammo-MLO\n",
            "113\n",
            "113\n",
            "Multiple or Montage\n",
            "320\n",
            "320\n",
            "NOS\n",
            "927\n",
            "927\n",
            "Oblique\n",
            "767\n",
            "767\n",
            "Other view\n",
            "846\n",
            "846\n",
            "PA\n",
            "1313\n",
            "1313\n",
            "3D Reconstruction\n",
            "232\n",
            "232\n",
            "Transverse\n",
            "490\n",
            "490\n",
            "Sagittal\n",
            "4357\n",
            "4357\n",
            "Decubitus\n",
            "17\n",
            "17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory_list = ['AP', 'Axial', 'Coronal', 'Frontal', 'Histology', 'Image-Plane','Lateral','Longitudinal',\n",
        "                  'Mammo-CC','Mammo-MagCC','Mammo-MLO','Multiple or Montage','NOS','Oblique','Other view','PA','3D Reconstruction', 'Transverse', 'Sagittal', 'Decubitus' ]\n",
        "\n",
        "for plane in directory_list:\n",
        "  print(plane)\n",
        "  current_path = dataset_path+'/'+plane\n",
        "  with open(f'{current_path}/cleaned_dataset.json', 'r', encoding='utf-8') as f:\n",
        "    try:\n",
        "        data = json.load(f)\n",
        "    except ValueError:\n",
        "        data = []\n",
        "  print(len(data))\n",
        "\n",
        "  added = []\n",
        "  new_data = []\n",
        "  for i in range(len(data)):\n",
        "    if data[i]['id'] not in added:\n",
        "      new_data.append(data[i])\n",
        "      added.append(data[i]['id'])\n",
        "  print(len(new_data))\n",
        "  save_to_json_file(current_path,new_data)\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b30FaqCcjHPr",
        "outputId": "4347f0c5-5af4-4bb3-af46-c380de417c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AP\n",
            "1446\n",
            "1446\n",
            "Axial\n",
            "7251\n",
            "7250\n",
            "Coronal\n",
            "5649\n",
            "2824\n",
            "Frontal\n",
            "1016\n",
            "1016\n",
            "Histology\n",
            "349\n",
            "348\n",
            "Image-Plane\n",
            "182\n",
            "182\n",
            "Lateral\n",
            "1165\n",
            "1165\n",
            "Longitudinal\n",
            "303\n",
            "300\n",
            "Mammo-CC\n",
            "116\n",
            "116\n",
            "Mammo-MagCC\n",
            "12\n",
            "12\n",
            "Mammo-MLO\n",
            "113\n",
            "113\n",
            "Multiple or Montage\n",
            "320\n",
            "320\n",
            "NOS\n",
            "927\n",
            "926\n",
            "Oblique\n",
            "767\n",
            "382\n",
            "Other view\n",
            "846\n",
            "423\n",
            "PA\n",
            "1313\n",
            "656\n",
            "3D Reconstruction\n",
            "232\n",
            "232\n",
            "Transverse\n",
            "490\n",
            "488\n",
            "Sagittal\n",
            "4357\n",
            "3031\n",
            "Decubitus\n",
            "17\n",
            "17\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}